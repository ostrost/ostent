* package internal

#+BEGIN_SRC sh :results raw
fst=../vendor/github.com/influxdata/telegraf/internal
snd=.

(diff --unified --ignore-all-space --recursive \
 "$fst/../agent" \
 "$snd/agent";
 diff --unified --ignore-all-space --recursive \
 "$fst" \
 "$snd") |
awk '{ if ($1 == "---" || $1 == "+++") { $_ = $1 FS $2; }; print }'
#+END_SRC

#+BEGIN_SRC diff
#+RESULTS:
diff --unified --ignore-all-space --recursive ../vendor/github.com/influxdata/telegraf/internal/../agent/accumulator.go ./agent/accumulator.go
--- ../vendor/github.com/influxdata/telegraf/internal/../agent/accumulator.go
+++ ./agent/accumulator.go
@@ -7,7 +7,8 @@
 	"time"
 
 	"github.com/influxdata/telegraf"
-	"github.com/influxdata/telegraf/internal/models"
+
+	internal_models "github.com/ostrost/ostent/internal/models"
 )
 
 func NewAccumulator(
Only in ../vendor/github.com/influxdata/telegraf/internal/../agent: accumulator_test.go
diff --unified --ignore-all-space --recursive ../vendor/github.com/influxdata/telegraf/internal/../agent/agent.go ./agent/agent.go
--- ../vendor/github.com/influxdata/telegraf/internal/../agent/agent.go
+++ ./agent/agent.go
@@ -1,7 +1,6 @@
 package agent
 
 import (
-	"fmt"
 	"log"
 	"os"
 	"runtime"
@@ -9,9 +8,9 @@
 	"time"
 
 	"github.com/influxdata/telegraf"
-	"github.com/influxdata/telegraf/internal"
-	"github.com/influxdata/telegraf/internal/config"
-	"github.com/influxdata/telegraf/internal/models"
+
+	"github.com/ostrost/ostent/internal/config"
+	internal_models "github.com/ostrost/ostent/internal/models"
 )
 
 // Agent runs telegraf and collects data based on the given config
@@ -103,7 +102,6 @@
 // gatherer runs the inputs that have been configured with their own
 // reporting interval.
 func (a *Agent) gatherer(
-	shutdown chan struct{},
 	input *internal_models.RunningInput,
 	interval time.Duration,
 	metricC chan telegraf.Metric,
@@ -122,10 +120,8 @@
 			a.Config.Agent.Interval.Duration)
 		acc.setDefaultTags(a.Config.Tags)
 
-		internal.RandomSleep(a.Config.Agent.CollectionJitter.Duration, shutdown)
-
 		start := time.Now()
-		gatherWithTimeout(shutdown, input, acc, interval)
+		gatherWithTimeout(input, acc, interval)
 		elapsed := time.Since(start)
 
 		if outerr != nil {
@@ -137,8 +133,6 @@
 		}
 
 		select {
-		case <-shutdown:
-			return nil
 		case <-ticker.C:
 			continue
 		}
@@ -151,7 +145,6 @@
 //   hung processes, and to prevent re-calling the same hung process over and
 //   over.
 func gatherWithTimeout(
-	shutdown chan struct{},
 	input *internal_models.RunningInput,
 	acc *accumulator,
 	timeout time.Duration,
@@ -175,60 +168,8 @@
 				"collection interval (%s)",
 				input.Name, timeout)
 			continue
-		case <-shutdown:
-			return
-		}
-	}
-}
-
-// Test verifies that we can 'Gather' from all inputs with their configured
-// Config struct
-func (a *Agent) Test() error {
-	shutdown := make(chan struct{})
-	defer close(shutdown)
-	metricC := make(chan telegraf.Metric)
-
-	// dummy receiver for the point channel
-	go func() {
-		for {
-			select {
-			case <-metricC:
-				// do nothing
-			case <-shutdown:
-				return
-			}
-		}
-	}()
-
-	for _, input := range a.Config.Inputs {
-		acc := NewAccumulator(input.Config, metricC)
-		acc.SetTrace(true)
-		acc.SetPrecision(a.Config.Agent.Precision.Duration,
-			a.Config.Agent.Interval.Duration)
-		acc.setDefaultTags(a.Config.Tags)
-
-		fmt.Printf("* Plugin: %s, Collection 1\n", input.Name)
-		if input.Config.Interval != 0 {
-			fmt.Printf("* Internal: %s\n", input.Config.Interval)
-		}
-
-		if err := input.Input.Gather(acc); err != nil {
-			return err
-		}
-
-		// Special instructions for some inputs. cpu, for example, needs to be
-		// run twice in order to return cpu usage percentages.
-		switch input.Name {
-		case "cpu", "mongodb", "procstat":
-			time.Sleep(500 * time.Millisecond)
-			fmt.Printf("* Plugin: %s, Collection 2\n", input.Name)
-			if err := input.Input.Gather(acc); err != nil {
-				return err
 			}
 		}
-
-	}
-	return nil
 }
 
 // flush writes a list of metrics to all configured outputs
@@ -251,7 +192,7 @@
 }
 
 // flusher monitors the metrics input channel and flushes on the minimum interval
-func (a *Agent) flusher(shutdown chan struct{}, metricC chan telegraf.Metric) error {
+func (a *Agent) flusher(metricC chan telegraf.Metric) error {
 	// Inelegant, but this sleep is to allow the Gather threads to run, so that
 	// the flusher will flush after metrics are collected.
 	time.Sleep(time.Millisecond * 200)
@@ -260,12 +201,7 @@
 
 	for {
 		select {
-		case <-shutdown:
-			log.Println("Hang on, flushing any cached metrics before shutdown")
-			a.flush()
-			return nil
 		case <-ticker.C:
-			internal.RandomSleep(a.Config.Agent.FlushJitter.Duration, shutdown)
 			a.flush()
 		case m := <-metricC:
 			for i, o := range a.Config.Outputs {
@@ -296,14 +232,9 @@
 }
 
 // Run runs the agent daemon, gathering every Interval
-func (a *Agent) Run(shutdown chan struct{}) error {
+func (a *Agent) Run() error {
 	var wg sync.WaitGroup
 
-	log.Printf("Agent Config: Interval:%s, Debug:%#v, Quiet:%#v, Hostname:%#v, "+
-		"Flush Interval:%s \n",
-		a.Config.Agent.Interval.Duration, a.Config.Agent.Debug, a.Config.Agent.Quiet,
-		a.Config.Agent.Hostname, a.Config.Agent.FlushInterval.Duration)
-
 	// channel shared between all input threads for accumulating metrics
 	metricC := make(chan telegraf.Metric, 10000)
 
@@ -327,7 +258,7 @@
 	}
 
 	// Round collection to nearest interval by sleeping
-	if a.Config.Agent.RoundInterval {
+	if true { // TODO  if a.Config.Agent.RoundInterval
 		i := int64(a.Config.Agent.Interval.Duration)
 		time.Sleep(time.Duration(i - (time.Now().UnixNano() % i)))
 	}
@@ -335,9 +266,8 @@
 	wg.Add(1)
 	go func() {
 		defer wg.Done()
-		if err := a.flusher(shutdown, metricC); err != nil {
+		if err := a.flusher(metricC); err != nil {
 			log.Printf("Flusher routine failed, exiting: %s\n", err.Error())
-			close(shutdown)
 		}
 	}()
 
@@ -350,7 +280,7 @@
 		}
 		go func(in *internal_models.RunningInput, interv time.Duration) {
 			defer wg.Done()
-			if err := a.gatherer(shutdown, in, interv, metricC); err != nil {
+			if err := a.gatherer(in, interv, metricC); err != nil {
 				log.Printf(err.Error())
 			}
 		}(input, interval)
@@ -359,3 +289,25 @@
 	wg.Wait()
 	return nil
 }
+
+func Run(c *config.Config) error {
+	// if err := c.LoadConfig( ... ); err != nil { return err }
+
+	a, err := NewAgent(c)
+	if err != nil {
+		return err
+	}
+
+	if err := a.Connect(); err != nil {
+		return err
+	}
+	/* There will be loop with waiting for reload signal.
+	reload := make(chan bool, 1)
+	reload <- true
+	for <-reload {
+		reload <- false // */
+	if err := a.Run(); err != nil {
+		return err
+	}
+	return nil
+}
Only in ../vendor/github.com/influxdata/telegraf/internal/../agent: agent_test.go
Only in .: README.org
Only in .: agent
Only in ../vendor/github.com/influxdata/telegraf/internal/buffer: buffer_test.go
Only in ../vendor/github.com/influxdata/telegraf/internal/config: aws
diff --unified --ignore-all-space --recursive ../vendor/github.com/influxdata/telegraf/internal/config/config.go ./config/config.go
--- ../vendor/github.com/influxdata/telegraf/internal/config/config.go
+++ ./config/config.go
@@ -2,30 +2,29 @@
 
 import (
 	"bytes"
-	"errors"
 	"fmt"
 	"io/ioutil"
 	"log"
 	"os"
-	"path/filepath"
 	"regexp"
-	"sort"
 	"strings"
 	"time"
 
-	"github.com/influxdata/telegraf"
-	"github.com/influxdata/telegraf/internal"
-	"github.com/influxdata/telegraf/internal/models"
 	"github.com/influxdata/telegraf/plugins/inputs"
 	"github.com/influxdata/telegraf/plugins/outputs"
-	"github.com/influxdata/telegraf/plugins/parsers"
 	"github.com/influxdata/telegraf/plugins/serializers"
 
-	"github.com/influxdata/config"
 	"github.com/influxdata/toml"
 	"github.com/influxdata/toml/ast"
+
+	"github.com/ostrost/ostent/internal"
+	internal_models "github.com/ostrost/ostent/internal/models"
 )
 
+var config = struct {
+	UnmarshalTable func(*ast.Table, interface{}) error
+}{UnmarshalTable: toml.UnmarshalTable}
+
 var (
 	// Default input plugins
 	inputDefaults = []string{"cpu", "mem", "swap", "system", "kernel",
@@ -56,13 +55,10 @@
 		// Agent defaults:
 		Agent: &AgentConfig{
 			Interval:      internal.Duration{Duration: 10 * time.Second},
-			RoundInterval: true,
 			FlushInterval: internal.Duration{Duration: 10 * time.Second},
 		},
 
 		Tags:          make(map[string]string),
-		Inputs:        make([]*internal_models.RunningInput, 0),
-		Outputs:       make([]*internal_models.RunningOutput, 0),
 		InputFilters:  make([]string, 0),
 		OutputFilters: make([]string, 0),
 	}
@@ -73,10 +69,6 @@
 	// Interval at which to gather information
 	Interval internal.Duration
 
-	// RoundInterval rounds collection interval to 'interval'.
-	//     ie, if Interval=10s then always collect on :00, :10, :20, etc.
-	RoundInterval bool
-
 	// By default, precision will be set to the same timestamp order as the
 	// collection interval, with the maximum being 1s.
 	//   ie, when interval = "10s", precision will be "1s"
@@ -85,21 +77,9 @@
 	// service input to set the timestamp at the appropriate precision.
 	Precision internal.Duration
 
-	// CollectionJitter is used to jitter the collection by a random amount.
-	// Each plugin will sleep for a random time within jitter before collecting.
-	// This can be used to avoid many plugins querying things like sysfs at the
-	// same time, which can have a measurable effect on the system.
-	CollectionJitter internal.Duration
-
 	// FlushInterval is the Interval at which to flush data
 	FlushInterval internal.Duration
 
-	// FlushJitter Jitters the flush interval by a random amount.
-	// This is primarily to avoid large write spikes for users running a large
-	// number of telegraf instances.
-	// ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
-	FlushJitter internal.Duration
-
 	// MetricBatchSize is the maximum number of metrics that is wrote to an
 	// output plugin in one call.
 	MetricBatchSize int
@@ -111,16 +91,6 @@
 	// not be less than 2 times MetricBatchSize.
 	MetricBufferLimit int
 
-	// FlushBufferWhenFull tells Telegraf to flush the metric buffer whenever
-	// it fills up, regardless of FlushInterval. Setting this option to true
-	// does _not_ deactivate FlushInterval.
-	FlushBufferWhenFull bool
-
-	// TODO(cam): Remove UTC and parameter, they are no longer
-	// valid for the agent config. Leaving them here for now for backwards-
-	// compatability
-	UTC bool `toml:"utc"`
-
 	// Debug is the option for running in debug mode
 	Debug bool
 
@@ -130,249 +100,6 @@
 	OmitHostname bool
 }
 
-// Inputs returns a list of strings of the configured inputs.
-func (c *Config) InputNames() []string {
-	var name []string
-	for _, input := range c.Inputs {
-		name = append(name, input.Name)
-	}
-	return name
-}
-
-// Outputs returns a list of strings of the configured inputs.
-func (c *Config) OutputNames() []string {
-	var name []string
-	for _, output := range c.Outputs {
-		name = append(name, output.Name)
-	}
-	return name
-}
-
-// ListTags returns a string of tags specified in the config,
-// line-protocol style
-func (c *Config) ListTags() string {
-	var tags []string
-
-	for k, v := range c.Tags {
-		tags = append(tags, fmt.Sprintf("%s=%s", k, v))
-	}
-
-	sort.Strings(tags)
-
-	return strings.Join(tags, " ")
-}
-
-var header = `# Telegraf Configuration
-#
-# Telegraf is entirely plugin driven. All metrics are gathered from the
-# declared inputs, and sent to the declared outputs.
-#
-# Plugins must be declared in here to be active.
-# To deactivate a plugin, comment out the name and any variables.
-#
-# Use 'telegraf -config telegraf.conf -test' to see what metrics a config
-# file would generate.
-#
-# Environment variables can be used anywhere in this config file, simply prepend
-# them with $. For strings the variable must be within quotes (ie, "$STR_VAR"),
-# for numbers and booleans they should be plain (ie, $INT_VAR, $BOOL_VAR)
-
-
-# Global tags can be specified here in key="value" format.
-[global_tags]
-  # dc = "us-east-1" # will tag all metrics with dc=us-east-1
-  # rack = "1a"
-  ## Environment variables can be used as tags, and throughout the config file
-  # user = "$USER"
-
-
-# Configuration for telegraf agent
-[agent]
-  ## Default data collection interval for all inputs
-  interval = "10s"
-  ## Rounds collection interval to 'interval'
-  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
-  round_interval = true
-
-  ## Telegraf will send metrics to outputs in batches of at
-  ## most metric_batch_size metrics.
-  metric_batch_size = 1000
-  ## For failed writes, telegraf will cache metric_buffer_limit metrics for each
-  ## output, and will flush this buffer on a successful write. Oldest metrics
-  ## are dropped first when this buffer fills.
-  metric_buffer_limit = 10000
-
-  ## Collection jitter is used to jitter the collection by a random amount.
-  ## Each plugin will sleep for a random time within jitter before collecting.
-  ## This can be used to avoid many plugins querying things like sysfs at the
-  ## same time, which can have a measurable effect on the system.
-  collection_jitter = "0s"
-
-  ## Default flushing interval for all outputs. You shouldn't set this below
-  ## interval. Maximum flush_interval will be flush_interval + flush_jitter
-  flush_interval = "10s"
-  ## Jitter the flush interval by a random amount. This is primarily to avoid
-  ## large write spikes for users running a large number of telegraf instances.
-  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
-  flush_jitter = "0s"
-
-  ## By default, precision will be set to the same timestamp order as the
-  ## collection interval, with the maximum being 1s.
-  ## Precision will NOT be used for service inputs, such as logparser and statsd.
-  ## Valid values are "Nns", "Nus" (or "NÂµs"), "Nms", "Ns".
-  precision = ""
-  ## Run telegraf in debug mode
-  debug = false
-  ## Run telegraf in quiet mode
-  quiet = false
-  ## Override default hostname, if empty use os.Hostname()
-  hostname = ""
-  ## If set to true, do no set the "host" tag in the telegraf agent.
-  omit_hostname = false
-
-
-###############################################################################
-#                            OUTPUT PLUGINS                                   #
-###############################################################################
-`
-
-var inputHeader = `
-
-###############################################################################
-#                            INPUT PLUGINS                                    #
-###############################################################################
-`
-
-var serviceInputHeader = `
-
-###############################################################################
-#                            SERVICE INPUT PLUGINS                            #
-###############################################################################
-`
-
-// PrintSampleConfig prints the sample config
-func PrintSampleConfig(inputFilters []string, outputFilters []string) {
-	fmt.Printf(header)
-
-	if len(outputFilters) != 0 {
-		printFilteredOutputs(outputFilters, false)
-	} else {
-		printFilteredOutputs(outputDefaults, false)
-		// Print non-default outputs, commented
-		var pnames []string
-		for pname := range outputs.Outputs {
-			if !sliceContains(pname, outputDefaults) {
-				pnames = append(pnames, pname)
-			}
-		}
-		sort.Strings(pnames)
-		printFilteredOutputs(pnames, true)
-	}
-
-	fmt.Printf(inputHeader)
-	if len(inputFilters) != 0 {
-		printFilteredInputs(inputFilters, false)
-	} else {
-		printFilteredInputs(inputDefaults, false)
-		// Print non-default inputs, commented
-		var pnames []string
-		for pname := range inputs.Inputs {
-			if !sliceContains(pname, inputDefaults) {
-				pnames = append(pnames, pname)
-			}
-		}
-		sort.Strings(pnames)
-		printFilteredInputs(pnames, true)
-	}
-}
-
-func printFilteredInputs(inputFilters []string, commented bool) {
-	// Filter inputs
-	var pnames []string
-	for pname := range inputs.Inputs {
-		if sliceContains(pname, inputFilters) {
-			pnames = append(pnames, pname)
-		}
-	}
-	sort.Strings(pnames)
-
-	// cache service inputs to print them at the end
-	servInputs := make(map[string]telegraf.ServiceInput)
-	// for alphabetical looping:
-	servInputNames := []string{}
-
-	// Print Inputs
-	for _, pname := range pnames {
-		creator := inputs.Inputs[pname]
-		input := creator()
-
-		switch p := input.(type) {
-		case telegraf.ServiceInput:
-			servInputs[pname] = p
-			servInputNames = append(servInputNames, pname)
-			continue
-		}
-
-		printConfig(pname, input, "inputs", commented)
-	}
-
-	// Print Service Inputs
-	if len(servInputs) == 0 {
-		return
-	}
-	sort.Strings(servInputNames)
-	fmt.Printf(serviceInputHeader)
-	for _, name := range servInputNames {
-		printConfig(name, servInputs[name], "inputs", commented)
-	}
-}
-
-func printFilteredOutputs(outputFilters []string, commented bool) {
-	// Filter outputs
-	var onames []string
-	for oname := range outputs.Outputs {
-		if sliceContains(oname, outputFilters) {
-			onames = append(onames, oname)
-		}
-	}
-	sort.Strings(onames)
-
-	// Print Outputs
-	for _, oname := range onames {
-		creator := outputs.Outputs[oname]
-		output := creator()
-		printConfig(oname, output, "outputs", commented)
-	}
-}
-
-type printer interface {
-	Description() string
-	SampleConfig() string
-}
-
-func printConfig(name string, p printer, op string, commented bool) {
-	comment := ""
-	if commented {
-		comment = "# "
-	}
-	fmt.Printf("\n%s# %s\n%s[[%s.%s]]", comment, p.Description(), comment,
-		op, name)
-
-	config := p.SampleConfig()
-	if config == "" {
-		fmt.Printf("\n%s  # no configuration\n\n", comment)
-	} else {
-		lines := strings.Split(config, "\n")
-		for i, line := range lines {
-			if i == 0 || i == len(lines)-1 {
-				fmt.Print("\n")
-				continue
-			}
-			fmt.Print(strings.TrimRight(comment+line, " ") + "\n")
-		}
-	}
-}
-
 func sliceContains(name string, list []string) bool {
 	for _, b := range list {
 		if b == name {
@@ -382,81 +109,28 @@
 	return false
 }
 
-// PrintInputConfig prints the config usage of a single input.
-func PrintInputConfig(name string) error {
-	if creator, ok := inputs.Inputs[name]; ok {
-		printConfig(name, creator(), "inputs", false)
-	} else {
-		return errors.New(fmt.Sprintf("Input %s not found", name))
-	}
-	return nil
-}
-
-// PrintOutputConfig prints the config usage of a single output.
-func PrintOutputConfig(name string) error {
-	if creator, ok := outputs.Outputs[name]; ok {
-		printConfig(name, creator(), "outputs", false)
-	} else {
-		return errors.New(fmt.Sprintf("Output %s not found", name))
-	}
-	return nil
-}
-
-func (c *Config) LoadDirectory(path string) error {
-	directoryEntries, err := ioutil.ReadDir(path)
-	if err != nil {
-		return err
-	}
-	for _, entry := range directoryEntries {
-		if entry.IsDir() {
-			continue
-		}
-		name := entry.Name()
-		if len(name) < 6 || name[len(name)-5:] != ".conf" {
-			continue
-		}
-		err := c.LoadConfig(filepath.Join(path, name))
-		if err != nil {
-			return err
-		}
-	}
-	return nil
-}
-
-// Try to find a default config file at these locations (in order):
-//   1. $TELEGRAF_CONFIG_PATH
-//   2. $HOME/.telegraf/telegraf.conf
-//   3. /etc/telegraf/telegraf.conf
-//
-func getDefaultConfigPath() (string, error) {
-	envfile := os.Getenv("TELEGRAF_CONFIG_PATH")
-	homefile := os.ExpandEnv("${HOME}/.telegraf/telegraf.conf")
-	etcfile := "/etc/telegraf/telegraf.conf"
-	for _, path := range []string{envfile, homefile, etcfile} {
-		if _, err := os.Stat(path); err == nil {
-			log.Printf("Using config file: %s", path)
-			return path, nil
-		}
-	}
-
-	// if we got here, we didn't find a file in a default location
-	return "", fmt.Errorf("No config file specified, and could not find one"+
-		" in $TELEGRAF_CONFIG_PATH, %s, or %s", homefile, etcfile)
-}
-
 // LoadConfig loads the given config file and applies it to c
 func (c *Config) LoadConfig(path string) error {
 	var err error
 	if path == "" {
+		return fmt.Errorf("No config file specified")
+		/*
 		if path, err = getDefaultConfigPath(); err != nil {
 			return err
 		}
+		*/
 	}
 	tbl, err := parseFile(path)
 	if err != nil {
 		return fmt.Errorf("Error parsing %s, %s", path, err)
 	}
 
+	return c.LoadTable(path, tbl)
+}
+
+func (c *Config) LoadTable(path string, tbl *ast.Table) error {
+	var err error
+
 	// Parse tags tables first:
 	for _, tableName := range []string{"tags", "global_tags"} {
 		if val, ok := tbl.Fields[tableName]; ok {
@@ -554,6 +228,10 @@
 	if err != nil {
 		return nil, err
 	}
+	return parseContents(contents)
+}
+
+func parseContents(contents []byte) (*ast.Table, error) {
 	// ugh windows why
 	contents = trimBOM(contents)
 
@@ -586,6 +264,9 @@
 		if err != nil {
 			return err
 		}
+		if serializer == nil {
+			return fmt.Errorf("Serializer is nil")
+		}
 		t.SetSerializer(serializer)
 	}
 
@@ -618,18 +299,6 @@
 		return fmt.Errorf("Undefined but requested input: %s", name)
 	}
 	input := creator()
-
-	// If the input has a SetParser function, then this means it can accept
-	// arbitrary types of input, so build the parser and set it.
-	switch t := input.(type) {
-	case parsers.ParserInput:
-		parser, err := buildParser(name, table)
-		if err != nil {
-			return err
-		}
-		t.SetParser(parser)
-	}
-
 	pluginConfig, err := buildInput(name, table)
 	if err != nil {
 		return err
@@ -791,9 +460,15 @@
 	return f, nil
 }
 
-// buildInput parses input specific items from the ast.Table,
-// builds the filter and returns a
-// internal_models.InputConfig to be inserted into internal_models.RunningInput
+// buildSerializer grabs the necessary entries from the ast.Table for creating
+// a serializers.Serializer object, and creates it, which can then be added onto
+// an Output object.
+func buildSerializer(name string, tbl *ast.Table) (serializers.Serializer, error) {
+	return serializers.NewSerializer(&serializers.Config{
+		DataFormat: "graphite",
+	})
+}
+
 func buildInput(name string, tbl *ast.Table) (*internal_models.InputConfig, error) {
 	cp := &internal_models.InputConfig{Name: name}
 	if node, ok := tbl.Fields["interval"]; ok {
@@ -855,118 +530,6 @@
 	return cp, nil
 }
 
-// buildParser grabs the necessary entries from the ast.Table for creating
-// a parsers.Parser object, and creates it, which can then be added onto
-// an Input object.
-func buildParser(name string, tbl *ast.Table) (parsers.Parser, error) {
-	c := &parsers.Config{}
-
-	if node, ok := tbl.Fields["data_format"]; ok {
-		if kv, ok := node.(*ast.KeyValue); ok {
-			if str, ok := kv.Value.(*ast.String); ok {
-				c.DataFormat = str.Value
-			}
-		}
-	}
-
-	// Legacy support, exec plugin originally parsed JSON by default.
-	if name == "exec" && c.DataFormat == "" {
-		c.DataFormat = "json"
-	} else if c.DataFormat == "" {
-		c.DataFormat = "influx"
-	}
-
-	if node, ok := tbl.Fields["separator"]; ok {
-		if kv, ok := node.(*ast.KeyValue); ok {
-			if str, ok := kv.Value.(*ast.String); ok {
-				c.Separator = str.Value
-			}
-		}
-	}
-
-	if node, ok := tbl.Fields["templates"]; ok {
-		if kv, ok := node.(*ast.KeyValue); ok {
-			if ary, ok := kv.Value.(*ast.Array); ok {
-				for _, elem := range ary.Value {
-					if str, ok := elem.(*ast.String); ok {
-						c.Templates = append(c.Templates, str.Value)
-					}
-				}
-			}
-		}
-	}
-
-	if node, ok := tbl.Fields["tag_keys"]; ok {
-		if kv, ok := node.(*ast.KeyValue); ok {
-			if ary, ok := kv.Value.(*ast.Array); ok {
-				for _, elem := range ary.Value {
-					if str, ok := elem.(*ast.String); ok {
-						c.TagKeys = append(c.TagKeys, str.Value)
-					}
-				}
-			}
-		}
-	}
-
-	if node, ok := tbl.Fields["data_type"]; ok {
-		if kv, ok := node.(*ast.KeyValue); ok {
-			if str, ok := kv.Value.(*ast.String); ok {
-				c.DataType = str.Value
-			}
-		}
-	}
-
-	c.MetricName = name
-
-	delete(tbl.Fields, "data_format")
-	delete(tbl.Fields, "separator")
-	delete(tbl.Fields, "templates")
-	delete(tbl.Fields, "tag_keys")
-	delete(tbl.Fields, "data_type")
-
-	return parsers.NewParser(c)
-}
-
-// buildSerializer grabs the necessary entries from the ast.Table for creating
-// a serializers.Serializer object, and creates it, which can then be added onto
-// an Output object.
-func buildSerializer(name string, tbl *ast.Table) (serializers.Serializer, error) {
-	c := &serializers.Config{}
-
-	if node, ok := tbl.Fields["data_format"]; ok {
-		if kv, ok := node.(*ast.KeyValue); ok {
-			if str, ok := kv.Value.(*ast.String); ok {
-				c.DataFormat = str.Value
-			}
-		}
-	}
-
-	if c.DataFormat == "" {
-		c.DataFormat = "influx"
-	}
-
-	if node, ok := tbl.Fields["prefix"]; ok {
-		if kv, ok := node.(*ast.KeyValue); ok {
-			if str, ok := kv.Value.(*ast.String); ok {
-				c.Prefix = str.Value
-			}
-		}
-	}
-
-	if node, ok := tbl.Fields["template"]; ok {
-		if kv, ok := node.(*ast.KeyValue); ok {
-			if str, ok := kv.Value.(*ast.String); ok {
-				c.Template = str.Value
-			}
-		}
-	}
-
-	delete(tbl.Fields, "data_format")
-	delete(tbl.Fields, "prefix")
-	delete(tbl.Fields, "template")
-	return serializers.NewSerializer(c)
-}
-
 // buildOutput parses output specific items from the ast.Table,
 // builds the filter and returns an
 // internal_models.OutputConfig to be inserted into internal_models.RunningInput
@@ -989,3 +552,27 @@
 	}
 	return oc, nil
 }
+
+func (c *Config) LoadInterface(path string, in interface{}) error {
+	text, err := toml.Marshal(in)
+	if err != nil {
+		return err
+	}
+	lines := strings.Split(string(text), "\n")
+	for _, replace := range [][2]string{
+		{"password=", "********"},
+		{"api_token=", "****************"},
+	} {
+		for i := range lines {
+			if strings.HasPrefix(lines[i], replace[0]) {
+				lines[i] = fmt.Sprintf("%s=\"%s\"", replace[0], replace[1])
+			}
+		}
+	}
+	log.Printf("#%s.toml:\n%s", path, strings.Join(lines, "\n"))
+	tbl, err := parseContents(text)
+	if err != nil {
+		return err
+	}
+	return c.LoadTable(path, tbl)
+}
Only in ../vendor/github.com/influxdata/telegraf/internal/config: config_test.go
Only in ../vendor/github.com/influxdata/telegraf/internal/config: testdata
Only in ../vendor/github.com/influxdata/telegraf/internal: errchan
Only in ../vendor/github.com/influxdata/telegraf/internal: globpath
diff --unified --ignore-all-space --recursive ../vendor/github.com/influxdata/telegraf/internal/internal.go ./internal.go
--- ../vendor/github.com/influxdata/telegraf/internal/internal.go
+++ ./internal.go
@@ -1,30 +1,8 @@
 package internal
 
 import (
-	"bufio"
-	"bytes"
-	"crypto/rand"
-	"crypto/tls"
-	"crypto/x509"
-	"errors"
-	"fmt"
-	"io/ioutil"
-	"log"
-	"math/big"
-	"os"
-	"os/exec"
 	"strconv"
-	"strings"
 	"time"
-	"unicode"
-)
-
-const alphanum string = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"
-
-var (
-	TimeoutErr = errors.New("Command timed out.")
-
-	NotImplementedError = errors.New("not implemented yet")
 )
 
 // Duration just wraps time.Duration
@@ -56,177 +34,3 @@
 
 	return nil
 }
-
-// ReadLines reads contents from a file and splits them by new lines.
-// A convenience wrapper to ReadLinesOffsetN(filename, 0, -1).
-func ReadLines(filename string) ([]string, error) {
-	return ReadLinesOffsetN(filename, 0, -1)
-}
-
-// ReadLines reads contents from file and splits them by new line.
-// The offset tells at which line number to start.
-// The count determines the number of lines to read (starting from offset):
-//   n >= 0: at most n lines
-//   n < 0: whole file
-func ReadLinesOffsetN(filename string, offset uint, n int) ([]string, error) {
-	f, err := os.Open(filename)
-	if err != nil {
-		return []string{""}, err
-	}
-	defer f.Close()
-
-	var ret []string
-
-	r := bufio.NewReader(f)
-	for i := 0; i < n+int(offset) || n < 0; i++ {
-		line, err := r.ReadString('\n')
-		if err != nil {
-			break
-		}
-		if i < int(offset) {
-			continue
-		}
-		ret = append(ret, strings.Trim(line, "\n"))
-	}
-
-	return ret, nil
-}
-
-// RandomString returns a random string of alpha-numeric characters
-func RandomString(n int) string {
-	var bytes = make([]byte, n)
-	rand.Read(bytes)
-	for i, b := range bytes {
-		bytes[i] = alphanum[b%byte(len(alphanum))]
-	}
-	return string(bytes)
-}
-
-// GetTLSConfig gets a tls.Config object from the given certs, key, and CA files.
-// you must give the full path to the files.
-// If all files are blank and InsecureSkipVerify=false, returns a nil pointer.
-func GetTLSConfig(
-	SSLCert, SSLKey, SSLCA string,
-	InsecureSkipVerify bool,
-) (*tls.Config, error) {
-	if SSLCert == "" && SSLKey == "" && SSLCA == "" && !InsecureSkipVerify {
-		return nil, nil
-	}
-
-	t := &tls.Config{
-		InsecureSkipVerify: InsecureSkipVerify,
-	}
-
-	if SSLCA != "" {
-		caCert, err := ioutil.ReadFile(SSLCA)
-		if err != nil {
-			return nil, errors.New(fmt.Sprintf("Could not load TLS CA: %s",
-				err))
-		}
-
-		caCertPool := x509.NewCertPool()
-		caCertPool.AppendCertsFromPEM(caCert)
-		t.RootCAs = caCertPool
-	}
-
-	if SSLCert != "" && SSLKey != "" {
-		cert, err := tls.LoadX509KeyPair(SSLCert, SSLKey)
-		if err != nil {
-			return nil, errors.New(fmt.Sprintf(
-				"Could not load TLS client key/certificate from %s:%s: %s",
-				SSLKey, SSLCert, err))
-		}
-
-		t.Certificates = []tls.Certificate{cert}
-		t.BuildNameToCertificate()
-	}
-
-	// will be nil by default if nothing is provided
-	return t, nil
-}
-
-// SnakeCase converts the given string to snake case following the Golang format:
-// acronyms are converted to lower-case and preceded by an underscore.
-func SnakeCase(in string) string {
-	runes := []rune(in)
-	length := len(runes)
-
-	var out []rune
-	for i := 0; i < length; i++ {
-		if i > 0 && unicode.IsUpper(runes[i]) && ((i+1 < length && unicode.IsLower(runes[i+1])) || unicode.IsLower(runes[i-1])) {
-			out = append(out, '_')
-		}
-		out = append(out, unicode.ToLower(runes[i]))
-	}
-
-	return string(out)
-}
-
-// CombinedOutputTimeout runs the given command with the given timeout and
-// returns the combined output of stdout and stderr.
-// If the command times out, it attempts to kill the process.
-func CombinedOutputTimeout(c *exec.Cmd, timeout time.Duration) ([]byte, error) {
-	var b bytes.Buffer
-	c.Stdout = &b
-	c.Stderr = &b
-	if err := c.Start(); err != nil {
-		return nil, err
-	}
-	err := WaitTimeout(c, timeout)
-	return b.Bytes(), err
-}
-
-// RunTimeout runs the given command with the given timeout.
-// If the command times out, it attempts to kill the process.
-func RunTimeout(c *exec.Cmd, timeout time.Duration) error {
-	if err := c.Start(); err != nil {
-		return err
-	}
-	return WaitTimeout(c, timeout)
-}
-
-// WaitTimeout waits for the given command to finish with a timeout.
-// It assumes the command has already been started.
-// If the command times out, it attempts to kill the process.
-func WaitTimeout(c *exec.Cmd, timeout time.Duration) error {
-	timer := time.NewTimer(timeout)
-	done := make(chan error)
-	go func() { done <- c.Wait() }()
-	select {
-	case err := <-done:
-		timer.Stop()
-		return err
-	case <-timer.C:
-		if err := c.Process.Kill(); err != nil {
-			log.Printf("FATAL error killing process: %s", err)
-			return err
-		}
-		// wait for the command to return after killing it
-		<-done
-		return TimeoutErr
-	}
-}
-
-// RandomSleep will sleep for a random amount of time up to max.
-// If the shutdown channel is closed, it will return before it has finished
-// sleeping.
-func RandomSleep(max time.Duration, shutdown chan struct{}) {
-	if max == 0 {
-		return
-	}
-	maxSleep := big.NewInt(max.Nanoseconds())
-
-	var sleepns int64
-	if j, err := rand.Int(rand.Reader, maxSleep); err == nil {
-		sleepns = j.Int64()
-	}
-
-	t := time.NewTimer(time.Nanosecond * time.Duration(sleepns))
-	select {
-	case <-t.C:
-		return
-	case <-shutdown:
-		t.Stop()
-		return
-	}
-}
Only in ../vendor/github.com/influxdata/telegraf/internal: internal_test.go
Only in ../vendor/github.com/influxdata/telegraf/internal: limiter
Only in ../vendor/github.com/influxdata/telegraf/internal/models: filter_test.go
diff --unified --ignore-all-space --recursive ../vendor/github.com/influxdata/telegraf/internal/models/running_output.go ./models/running_output.go
--- ../vendor/github.com/influxdata/telegraf/internal/models/running_output.go
+++ ./models/running_output.go
@@ -5,7 +5,8 @@
 	"time"
 
 	"github.com/influxdata/telegraf"
-	"github.com/influxdata/telegraf/internal/buffer"
+
+	"github.com/ostrost/ostent/internal/buffer"
 )
 
 const (
Only in ../vendor/github.com/influxdata/telegraf/internal/models: running_output_test.go
Only in .: plugins
#+END_SRC
